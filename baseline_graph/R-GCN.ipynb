{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd  # To read data\n",
    "from math import log\n",
    "\n",
    "import csv\n",
    "import webbrowser\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from dgl import DGLGraph\n",
    "import dgl.function as fn\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_datasets import load_banned\n",
    "from load_datasets import load_graph\n",
    "from load_datasets import get_banned_ids, banned_sub_in_G, get_random_subgraph\n",
    "import random\n",
    "\n",
    "DATASET = 'title' \n",
    "\n",
    "# lists of strings, which are the names of banned subreddits to train and test on\n",
    "TESTING, TRAINING = [], []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # load graph and maps that are used to map ids (int) to subreddit names (str)\n",
    "  G, id_to_subreddit, subreddit_to_id = load_graph(DATASET)\n",
    "  # load banned subreddits [str]\n",
    "  banned = load_banned()\n",
    "  # get banned subreddits that appear in G\n",
    "  banned = banned_sub_in_G(G, id_to_subreddit, banned)\n",
    "  # get list of random sample of banned subreddits to train on. \n",
    "  TRAINING = random.sample(banned, int(len(banned) * 3 / 4))\n",
    "  # rest of subreddits are for testing.\n",
    "  TESTING = list(set(banned) - set(TRAINING))\n",
    "  # generate subgraph of G\n",
    "  G_new = get_random_subgraph(G, get_banned_ids(TRAINING, subreddit_to_id))\n",
    "  print('number of nodes in random subgraph: ', G_new.GetNodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNLayer(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, num_rels, num_bases=-1, bias=None,\n",
    "                 activation=None, is_input_layer=False):\n",
    "        super(RGCNLayer, self).__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.num_rels = num_rels\n",
    "        self.num_bases = num_bases\n",
    "        self.bias = bias\n",
    "        self.activation = activation\n",
    "        self.is_input_layer = is_input_layer\n",
    "\n",
    "        # sanity check\n",
    "        if self.num_bases <= 0 or self.num_bases > self.num_rels:\n",
    "            self.num_bases = self.num_rels\n",
    "\n",
    "        # weight bases in equation (3)\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.num_bases, self.in_feat,\n",
    "                                                self.out_feat))\n",
    "        if self.num_bases < self.num_rels:\n",
    "            # linear combination coefficients in equation (3)\n",
    "            self.w_comp = nn.Parameter(torch.Tensor(self.num_rels, self.num_bases))\n",
    "\n",
    "        # add bias\n",
    "        if self.bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_feat))\n",
    "\n",
    "        # init trainable parameters\n",
    "        nn.init.xavier_uniform_(self.weight,\n",
    "                                gain=nn.init.calculate_gain('relu'))\n",
    "        if self.num_bases < self.num_rels:\n",
    "            nn.init.xavier_uniform_(self.w_comp,\n",
    "                                    gain=nn.init.calculate_gain('relu'))\n",
    "        if self.bias:\n",
    "            nn.init.xavier_uniform_(self.bias,\n",
    "                                    gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def forward(self, g):\n",
    "        if self.num_bases < self.num_rels:\n",
    "            # generate all weights from bases (equation (3))\n",
    "            weight = self.weight.view(self.in_feat, self.num_bases, self.out_feat)\n",
    "            weight = torch.matmul(self.w_comp, weight).view(self.num_rels,\n",
    "                                                        self.in_feat, self.out_feat)\n",
    "        else:\n",
    "            weight = self.weight\n",
    "\n",
    "        if self.is_input_layer:\n",
    "            def message_func(edges):\n",
    "                # for input layer, matrix multiply can be converted to be\n",
    "                # an embedding lookup using source node id\n",
    "                embed = weight.view(-1, self.out_feat)\n",
    "                index = edges.data['rel_type'] * self.in_feat + edges.src['id']\n",
    "                return {'msg': embed[index] * edges.data['norm']}\n",
    "        else:\n",
    "            def message_func(edges):\n",
    "                w = weight[edges.data['rel_type']]\n",
    "                msg = torch.bmm(edges.src['h'].unsqueeze(1), w).squeeze()\n",
    "                msg = msg * edges.data['norm']\n",
    "                return {'msg': msg}\n",
    "\n",
    "        def apply_func(nodes):\n",
    "            h = nodes.data['h']\n",
    "            if self.bias:\n",
    "                h = h + self.bias\n",
    "            if self.activation:\n",
    "                h = self.activation(h)\n",
    "            return {'h': h}\n",
    "\n",
    "        g.update_all(message_func, fn.sum(msg='msg', out='h'), apply_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_nodes, h_dim, out_dim, num_rels,\n",
    "                 num_bases=-1, num_hidden_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.h_dim = h_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_rels = num_rels\n",
    "        self.num_bases = num_bases\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "        # create rgcn layers\n",
    "        self.build_model()\n",
    "\n",
    "        # create initial features\n",
    "        self.features = self.create_features()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.layers = nn.ModuleList()\n",
    "        # input to hidden\n",
    "        i2h = self.build_input_layer()\n",
    "        self.layers.append(i2h)\n",
    "        # hidden to hidden\n",
    "        for _ in range(self.num_hidden_layers):\n",
    "            h2h = self.build_hidden_layer()\n",
    "            self.layers.append(h2h)\n",
    "        # hidden to output\n",
    "        h2o = self.build_output_layer()\n",
    "        self.layers.append(h2o)\n",
    "\n",
    "    # initialize feature for each node\n",
    "    def create_features(self):\n",
    "        features = torch.arange(self.num_nodes)\n",
    "        return features\n",
    "\n",
    "    def build_input_layer(self):\n",
    "        return RGCNLayer(self.num_nodes, self.h_dim, self.num_rels, self.num_bases,\n",
    "                         activation=F.relu, is_input_layer=True)\n",
    "\n",
    "    def build_hidden_layer(self):\n",
    "        return RGCNLayer(self.h_dim, self.h_dim, self.num_rels, self.num_bases,\n",
    "                         activation=F.relu)\n",
    "\n",
    "    def build_output_layer(self):\n",
    "        return RGCNLayer(self.h_dim, self.out_dim, self.num_rels, self.num_bases,\n",
    "                         activation=partial(F.softmax, dim=1))\n",
    "\n",
    "    def forward(self, g):\n",
    "        if self.features is not None:\n",
    "            g.ndata['id'] = self.features\n",
    "        for layer in self.layers:\n",
    "            layer(g)\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges=pd.read_csv('title-data/snap-redditHyperlinks-title.csv', names = [\"source\",\"destination\"])\n",
    "convertName2Id=pd.read_csv('title-data/snap-subreddit-ids-title.csv', names = [\"name\",\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beatingwomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Braincels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CreepShots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CringeAnarchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DarkNetMarkets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name\n",
       "0    Beatingwomen\n",
       "1       Braincels\n",
       "2      CreepShots\n",
       "3   CringeAnarchy\n",
       "4  DarkNetMarkets"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banned=pd.read_csv('gcntestdata-cleaned.csv')\n",
    "banned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGraph(edges, N):\n",
    "    \"\"\"\n",
    "    :param - N: number of nodes\n",
    "\n",
    "    return type: snap.PUNGraph\n",
    "    \"\"\"\n",
    "    ############################################################################\n",
    "    # TODO: Your code here!\n",
    "    G1 = snap.TUNGraph.New()\n",
    "    for i in range(N):\n",
    "        G1.AddNode(i)\n",
    "    for index, row in edges.iterrows():\n",
    "        a = int(row['source'])\n",
    "        b = int(row['destination'])\n",
    "#         print(a)\n",
    "#         print(b)\n",
    "        G1.AddEdge(a, b)\n",
    "    Graph = snap.ConvertGraph(snap.PUNGraph, G1)\n",
    "    ############################################################################\n",
    "    return Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = makeGraph(edges, len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load graph data\n",
    "import numpy as np\n",
    "# data = load_data(dataset='aifb')\n",
    "num_nodes = G_new.GetNodes()\n",
    "num_rels = G_new.GetEdges()\n",
    "num_classes = 2\n",
    "labels = data.labels\n",
    "train_idx = TRAINING\n",
    "test =  TESTING\n",
    "# split training and validation set\n",
    "val_idx = TRAINING[:len(TRAINING) // 5]\n",
    "train_idx = train_idx[len(TRAINING) // 5:]\n",
    "\n",
    "# edge type and normalization factor\n",
    "edge_type = torch.from_numpy(data.edge_type)\n",
    "edge_norm = torch.from_numpy(data.edge_norm).unsqueeze(1)\n",
    "\n",
    "labels = torch.from_numpy(labels).view(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
